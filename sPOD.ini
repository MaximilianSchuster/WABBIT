;#########################################################################################
;#########################################################################################
;######################## WABBIT PARAMETER FILE TEMPLATE #################################
;#########################################################################################
; if you add new parameters, add them here.
; note values have to be declared "value=0;", with equal sign (=) and semicolon (;)
;#########################################################################################
;#########################################################################################
[Domain]
; 2D or 3D problem?
dim=2;
; box size of computational domain. [Lx Ly Lz]
domain_size=1 1;
; synchronization (on/off)on [x y z] domain boundaries
; (off (NON-PERIODIC): 0/false/yes | on (PERIODIC): 1/true/no)
periodic_BC=1 1;


[Blocks]
; size of each block, must be odd (17, 33, 65 etc)
number_block_nodes=17;
; ghost nodes for each block. It is possible that in current versions, one can only
; set even values
number_ghost_nodes=4;
; number of equations / components of state vector. Note you have to properly
; adjust this value for the physics module that you use.
; ACM: 3 (2D), 4 (3D)
; Convection: 1 (2D /3D)
number_equations=4;
; maximal number of trees in the forest:
max_forest_size=10;
; threshold value for thresholding wavelet coefficients
eps=1e-3;1e-4;
; treelevel bounds
max_treelevel=6;
min_treelevel=1;
; switch for mesh adaption, 1=on, ...=off
adapt_mesh=1;
; adaptive initial conditon? i.e. create grid to respect error bounds
; default is same value as adapt_mesh
adapt_inicond=1;
; in some situations, it is necessary to create the intial grid, and then refine it for a couple of times.
; for example if one does non-adaptive non-equidistant spatial convergence tests. default is 0.
inicond_refinements=0;
; block distribution for balancing (also used for start distribution)
; [equal | sfc_z | sfc_hilbert]
; equal -> simple uniformly distribution
; sfc_z  -> space filling curve -> z-curve
; sfc_hilbert -> hilbert space filling curve
block_dist=sfc_hilbert;
; it can be expensive to balance the load and cheaper to live with a slight imbalance.
; Therefore, you can call loadbalancing only every couple of time steps. This parameter
; should affect only the computational cost and not the result.
loadbalancing_frequ=1;
; coarsening indicator to be used in mesh adaptation [threshold-state-vector,random,threshold-vorticity]
; threshold-state-vector: evaluates wavelet criterion on components of state vector. specify below which ones.
; threshold-vorticity: evaluates wavelet criterion on vorticity
;random
;randomly coarse some blocks. used for testing. note we tag for coarsening
;only once in the first iteration
coarsening_indicator=threshold-state-vector;
; use normalization for eps or not? normalization is done with INFTY norm currently. default
; is no normalization (0). ATTENTION works only for ACM currently (TODO!)
eps_normalized=1;
; which components to use for coarsening_indicator? default is all components.
; active only if coarsening_indicator=threshold-state-vector. select the components, set as
; many as number_equations
threshold_state_vector_component=1 1 0;
; if this flag is set (1), then blocks on max level have to coarsen, even if their
; details are significant. This is equivalent to ensuring dealiasing. Hence, if set to 1,
; wabbit will evaluate the right hand side of your equation on max_treelevel, but in the mesh
; coarsening it will, regardless of the solution, downsample the result to max_treelevel-1. Your
; expected precision is thus max_treelevel-1, but the computational cost (derivatives and timestep)
; is on max_treelevel.
force_maxlevel_dealiasing=0;
; if desired, we perform more than one time step
; before adapting the grid again. this can further reduce the overhead of adaptivity
; Note: the non-linear terms can create finer scales than resolved on the grid. they
; are usually filtered by the coarsening/refinement round trip. So if you do more than one time step
; on the grid, consider using a filter. default is "1", which is the classical scheme
N_dt_per_grid=1;



[Saving]
; WABBIT is in charge of saving, but what is saved is controled by the physics modules.
; here, you need to tell WABBIT how many fields are saved and how they will be labeled.
; The physics modules are then in charge of providing the respective data to WABBIT. I.e.
; if the field is called "mask", WABBIT will ask the physics module to return the array
; "mask" and then save that to disk.
; how many fields are you going to save?
N_fields_saved=6;
; how are the fields labeled?
field_names=rho Ux Uy p vort mask;



[BRIDGE]
; type 1 if a bridge shell be created and 0 if not
connect_with_bridge=0;
; The following parameters are only needed if there is a bridge

; Usage of a common MPI_comm_world  (1,yes,true,T=true / 0,no,false,F=false)
bridgeCommonMPI=0;
; If bridgeFluidMaster is true WABBIT is seen as the master and will
; spawn (split off) the processes of the other MPI_WORLD
;  (1,yes,true,T=true / 0,no,false,F=false)
bridgeFluidMaster=1;
; Command to use to launch the particle program (name of the executable)
particleCommand=./pig;

[Debug]
; 1 ... debuging for time measurements and testcases is active,
debug=1;
; If set to 1, the code will issue a single XXXXXtimes.dat file per proc, where one
; can examine individual mpiranks manually. this file is written in every iteration.
; the IO cost on some machines can be substantial if many cores are used: better disable
; this functionality then. default is 0.
write_individual_timings=0;
test_ghost_nodes_synch=1;
test_treecode=0;
check_redundant_nodes=1;
