;------------------------------------------------------------
;------------ WABBIT PARAMETER FILE TEMPLATE ----------------
;------------------------------------------------------------
; if you add new parameters, add them here.
; note values have to be declared "value=0;", with equal sign (=) and semicolon (;)


[Domain]
; 2D or 3D problem?
dim=2;
; box size of computational domain. [Lx Ly Lz]
domain_size=0.8 0.4; 0.0;
; synchronization (on/off)on [x y z] domain boundaries
; (off (NON-PERIODIC): 0/false/yes | on (PERIODIC): 1/true/no)
periodic_BC=1 1;


[Blocks]
; size of each block, must be odd (17, 33, 65 etc),
; if given one value this is meant for all directions, or specify value for each direction
number_block_nodes=33 33; 33;
; ghost nodes for each block. It is possible that in current versions, one can only
; set even values
number_ghost_nodes=4;
; number of equations / components of state vector. Note you have to properly
; adjust this value for the physics module that you use.
; ACM: 3 (2D), 4 (3D)
; Convection: 1 (2D /3D)
number_equations=4;
; threshold value for thresholding wavelet coefficients
eps=1e-3;1e-4;
; treelevel bounds
max_treelevel=4;
min_treelevel=4;
; switch for mesh adaption, 1=on, ...=off
adapt_mesh=0;
; adaptive initial conditon? i.e. create grid to respect error bounds
; default is same value as adapt_mesh
adapt_inicond=1;
; in some situations, it is necessary to create the intial grid, and then refine it for a couple of times.
; for example if one does non-adaptive non-equidistant spatial convergence tests. default is 0.
inicond_refinements=0;
; block distribution for balancing (also used for start distribution)
; [equal | sfc_z | sfc_hilbert]
; equal -> simple uniformly distribution
; sfc_z  -> space filling curve -> z-curve
; sfc_hilbert -> hilbert space filling curve
block_dist=sfc_hilbert;
; it can be expensive to balance the load and cheaper to live with a slight imbalance.
; Therefore, you can call loadbalancing only every couple of time steps. This parameter
; should affect only the computational cost and not the result.
loadbalancing_frequ=1;
; coarsening indicator to be used in mesh adaptation [threshold-state-vector,random,threshold-vorticity]
; threshold-state-vector: evaluates wavelet criterion on components of state vector. specify below which ones.
; threshold-vorticity: evaluates wavelet criterion on vorticity
;random
;randomly coarse some blocks. used for testing. note we tag for coarsening
;only once in the first iteration
coarsening_indicator=threshold-state-vector;
; use normalization for eps or not? normalization is done with INFTY norm currently. default
; is no normalization (0). ATTENTION works only for ACM currently (TODO!)
eps_normalized=1;
; which components to use for coarsening_indicator? default is all components.
; active only if coarsening_indicator=threshold-state-vector. select the components, set as
; many as number_equations
threshold_state_vector_component=1 1 1 1;
; it can be useful to also use the mask function (if penalization is used) for grid adaptation.
; i.e. the grid is always at the finest level on mask interfaces. Careful though: the Penalization
; is implemented on physics-module level, i.e. it is not available for all modules.  If it is
; not available, the option is useless but can cause errors.
threshold_mask=0;
; if this flag is set (1), then blocks on max level have to coarsen, even if their
; details are significant. This is equivalent to ensuring dealiasing. Hence, if set to 1,
; wabbit will evaluate the right hand side of your equation on max_treelevel, but in the mesh
; coarsening it will, regardless of the solution, downsample the result to max_treelevel-1. Your
; expected precision is thus max_treelevel-1, but the computational cost (derivatives and timestep)
; is on max_treelevel.
force_maxlevel_dealiasing=0;
; if desired, we perform more than one time step
; before adapting the grid again. this can further reduce the overhead of adaptivity
; Note: the non-linear terms can create finer scales than resolved on the grid. they
; are usually filtered by the coarsening/refinement round trip. So if you do more than one time step
; on the grid, consider using a filter. default is "1", which is the classical scheme
N_dt_per_grid=1;


[Time]
; final time to reach in simulation
time_max=0.62e-3;
; maximum walltime allowed for simulations (in hours). The run will be stopped if this duration
; is exceeded. This is useful on real clusters, where the walltime of a job is limited, and the
; system kills the job regardless of whether we're done or not. If WABBIT itself ends execution,
; a backup is written and you can resume the simulation right where it stopped. Note you can also
; stop a run using the file "runtime_control" (set runtime_control=save_stop;)
walltime_max=999.9;
; number of time steps performed. if not set, default value is very large
nt=;
; CFL criterium (velocity). Note the time step dt is dictated by the physics modules: some eqns (like
; the heat eqn, which is not implemented) may not even have a CFL restriction.
CFL=1.0;
; CFL critierum for penalization (dt<=CFL_eta*C_eta), if VPM is used. For RungeKuttaGeneric schemes, the constant
; has to be < 1.0 (otherwise the code is unstable). For krylov schemes, it can be greater
; 1, but be careful about the error. This parameter is used by ACM physics module only.
CFL_eta=0.99;
; wabbit can save the heavy data (flow fiels) to HDF5. What is saved depends on the physics modules
; and the section [Saving]. Here you control WHEN you want to save the output: either after a fixed
; number of time steps [fixed_freq], or after a physical time interval [fixed_time]
write_method=fixed_time;
; if write_method=fixed_freq:
; write frequency for output, choose very large number for disabling output on disk
write_freq=;;
; if write_method=fixed_time:
; write time for output
write_time=1e-5;
; fixed time step. if the value is greater 0.0, then the time step is fixed no matter what.
; the setting from the physics modules, which usually decide about dt, are ignored and over-
; written. The default is 0.0, so not used. NOTE: WABBIT still will adjust dt to precisely match
; the time for saving and statistics and the final time, if any of those is not a multiple of dt_fixed.
; In that case, some time steps may be smaller in order to reach those times.
dt_fixed=1e-7;
; largest time step, if you want to set one. dt is always smaller than that, if the
; value is greater 0. default is 0.0, so not used. WABBIT overwrites the physics module dt
; by that value, if the timestep is larger than dt_max and dt_max > 0.
dt_max=0.01;
; time-step method. can be either "RungeKuttaGeneric" or "Krylov". In the former case,
; any explicit Runge-Kutta scheme can be set by using the Butcher-Tableau. (RK4 is default) In the latter,
; the number of Krylov subspaces M_krylov can be set.
; [ RungeKuttaGeneric, Krylov ]
time_step_method=RungeKuttaGeneric;
; if time_step_method is krylov, then you can specify the dimension of the krylov subspace
; below. If dynamic subspace dimensions are used, we interpret this number as the maximum
; number of spaces admissible (the method requires a lot of memory in general)
M_krylov=12;
; fixed or dynamic krylov subspace dimension:
; [ fixed, dynamic ]
krylov_subspace_dimension=fixed;
; if dynamic subspace dimensionality is used, provide the residuum threshold here. Note this is
; in general not an exact measure for the error, but rather a good indicator.
krylov_err_threshold=1.0e-3;
; butcher_tableau
; use your butcher_tableau for the Runge Kutta time step function
; e.g. RK4:
;Butcher_tableau=(/ 0.0 0.0 0.0 0.0 0.0 0.5 0.5 0.0 0.0 0.0 
;0.5 0.0 0.5 0.0 0.0
;0.0 0.0 0.0 1.0 0.0
;0.0 0.16666666666666666 0.33333333333333331 0.33333333333333331  0.16666666666666666 /)


[Physics]
; what physics module is used?
; [ACM-new, ConvDiff-new, navier_stokes]
physics_type=navier_stokes;
; decide if you want to start from a given configuration (i.e. Statevector)
; 1:true, 0:false and we start from the initial conditions dictated by the physics
; modue.
read_from_files=1;
; if read_from_files is true, WABBIT will try to start from the given files
input_files=rho_000000000000.h5 Ux_000000000000.h5 Uy_000000000000.h5 p_000000000000.h5;


[Saving]
; WABBIT is in charge of saving, but what is saved is controled by the physics modules.
; here, you need to tell WABBIT how many fields are saved and how they will be labeled.
; The physics modules are then in charge of providing the respective data to WABBIT. I.e.
; if the field is called "mask", WABBIT will ask the physics module to return the array
; "mask" and then save that to disk.
; how many fields are you going to save?
N_fields_saved=6;
; how are the fields labeled?
field_names=rho Ux Uy p vort mask; sigmax sigmay;


[Statistics]
; save every nsave time steps (leave empty to disable)
nsave_stats=;
; and every tsave physical time units (leave empty to disable)
tsave_stats=;

[Sponge]
C_sponge=1.0e-2;

[Navier_Stokes]
; choose your coordinate_system
;  + default cartesian 2D/3D = "cartesian"
;  + cylindrical 2D = "cylindrical"
Coordinate_system=cartesian;
; adiabatic coefficient
gamma_=1.1775;
; specific gas constant
Rs=287.05         ;for air
; prandtl number
Pr=0.71;
; dynamic viscosity
mu0=1e-8;
; dissipation, 1=on, ...=off
dissipation=1;
; case studies of the NStokes module:
; + simple_geometry: [triangle | cylinder | rhombus]
; + funnel
; + shock_tube: [sod_shock_tube| standing_shock | moving_shock]
; + pipe_flow
; + no: [pressure_blob | shear_layer | pressure_wave ]
case=plenum;

[Boundary_Conditions]
; NSTOKES 2D only: if you want to use boundary conditions, you
; can specify them here
; Remarks:
; 1. for non periodic BC you have to explicitly switch of
; the synchrinzation in the chosen direction
; 2. CURRENTLY: non periodic BC make use of the Sparse BLAS
; vector matrix multiplication, therefore you have to make sure
; that SBLAS is used during compile time
;-------------------------------------------------------------
; available BCs: in coordinate direction e_i
;   + symmetric-open -- symmetric BC in -e_i and open BC in +e_i
;   + symmetryAxis-wall -- adiabatic slip wall in -e_i and
;                           adiabatic non-slip wall in +e_i
;   + periodic
;   + wallopen
;----------------------
; choose BC on the corresponding boundary [x,y]
boundary_type=periodic periodic;
i you may choose reference values of the
; statevector for the open boundaries:
state_xminus=1.645 0 0 1e-7;
state_xplus=1.645 0 0 1e-7;


[Initial_Values]
inicond=case;

[Discretization]
; order of derivatives [ FD_2nd_central | FD_4th_central_optimized ]
order_discretization=FD_4th_central_optimized;
; order of refinement predictor [ multiresolution_4th | multiresolution_2nd ]
order_predictor=multiresolution_4th;
; filtering of equations. NOTE: the filters are PHYSICS MODULE SPECIFIC! Hence it depends on the module
; which values you can set here.
; cNS: [no_filter | explicit_5pt | explicit_7pt | explicit_9pt | explicit_11pt | bogey_shock | wavelet_filter]
; ACM: [no_filter | wavelet_filter ]
; ConvDiff: not implemented
filter_type=bogey_shock;
; filter frequency (note: set filter to no_filter if you want to disable filtering completely)
; Note our clumsy nomenclature: we mean filtering every "filter_freq" time steps
filter_freq=1;
; bogey shock detector threshold
r_th=1e-5;
; if threshold is reached bogey-filter will be switch on [tanh,abs]
switch=tanh;
; bogey-filter detection method
detector_method=divU
; write out sigma for every n filter iterations (if 0 then sigma is not written out)
save_filter_strength=1


[VPM]
; Volume penalization method to take obstacles into account without adapting the
; grid. Penalization is an equation-dependent addon. It can not be used with any
; RHS, if the RHS does not support it.
; flag for penalization (0/1)
penalization=1;
; smooth mask for penalization term [0,1]. If the obstacle moves, this flag should
; be set, and in static cases as well. hard masks with only 0 and 1 are deprecated but
; included for completeness. Note some mask functions may ignore this flag (the insects for example)
smooth_mask=1;
; penalization factor. Can be seen as porosity, so smaller values = harder walls
; Note for explicit time integration, dt < C_eta
C_eta=1e-6;

[Bridge] 
connect_with_bridge=0;
; The following parameters are only needed if there is a bridge

; Usage of a common MPI_comm_world  (1,yes,true,T=true / 0,no,false,F=false)
bridgeCommonMPI=0;
; If bridgeFluidMaster is true WABBIT is seen as the master and will
; spawn (split off) the processes of the other MPI_WORLD
;  (1,yes,true,T=true / 0,no,false,F=false)
bridgeFluidMaster=1;
; Command to use to launch the particle program (name of the executable)
particleCommand=./pig;


[Timing]
; If set to 1, the code will issue a single XXXXXtimes.dat file per proc, where one
; can examine individual mpiranks manually. this file is written in every iteration.
; the IO cost on some machines can be substantial if many cores are used: better disable
; this functionality then. default is 0.
write_individual_timings=1;

[Debug]
; check if the ghost node synchronization gives the right order, on a random
; grid. this test costs some CPU time but no memory. It is done only once at startup.
test_ghost_nodes_synch=1;
test_treecode=0;
; internal testing routine for the ghost nodes: allocates HUGE amounts of memory
check_redundant_nodes=0;

[plenum]
name=sfb_pdc; 
inlet_velocity=;
inlet_density=;
inlet_pressure=;
outlet_pressure=;
outlet_density=;
diameter_pip=0.4;
diameter_ple=0.4;
length_pip=0.8;
length_ple=0.0;
wall_thickness=0.04;
sponge_thickness=;
sponge_pressure=100000;
sponge_density=0.900025;
sponge_velocity=0 0 0;
temperature=300;
L_blade=0.1;
AoA=45.0;
n_blades=0;
gap_blade=0.1;
t_blade=0.01;
